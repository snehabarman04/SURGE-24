{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QGtXI2ossGQ",
        "outputId": "59ec9795-c134-43ae-9edf-fcdbc216d60a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir = '/content/drive/MyDrive/compiled_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6FMuSxQGF-1"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Update the data augmentation and normalization steps\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9jAWY2LaWbc",
        "outputId": "41647c7d-b05b-4474-feac-e3365003a32a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 121MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, datasets, transforms\n",
        "import os\n",
        "\n",
        "# Load the pre-trained ResNet-18 model\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Freeze all the layers except the final classification layer\n",
        "for name, param in model.named_parameters():\n",
        "    if \"fc\" in name:  # Unfreeze the final classification layer\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Modify the final layer to match the number of classes in your dataset (e.g., 2 classes)\n",
        "num_classes = 3  # Change this to match your dataset\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# Move the model to the GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)  # Only optimize the final layer\n",
        "\n",
        "# Define a learning rate scheduler\n",
        "from torch.optim import lr_scheduler\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12lqri_0uLwM"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Define a learning rate scheduler\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMVMwiO4Gbde"
      },
      "outputs": [],
      "source": [
        "# creating data loaders and image datasets\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfIoa4VxG7Df",
        "outputId": "2f583021-c945-4059-f898-a21ed70801f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train': 7720, 'val': 27}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "print(dataset_sizes)\n",
        "\n",
        "class_names = {0: \"NORMAL\", 1: \"PNEUMONIA\", 2:\"TUBERCULOSIS\"}\n",
        "class_names\n",
        "class_indices = {\"NORMAL\": 0, \"PNEUMONIA\": 1, \"TUBERCULOSIS\":2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXZ5kJycllhf",
        "outputId": "bb7b437e-c463-4363-9dcd-d2d12e506ba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.6292 Acc: 0.7460\n",
            "val Loss: 1.0569 Acc: 0.5556\n",
            "train Loss: 0.5592 Acc: 0.7868\n",
            "val Loss: 0.7057 Acc: 0.7037\n",
            "train Loss: 0.5317 Acc: 0.8022\n",
            "val Loss: 0.4275 Acc: 0.8148\n",
            "train Loss: 0.5716 Acc: 0.7902\n",
            "val Loss: 0.5547 Acc: 0.7778\n",
            "train Loss: 0.5400 Acc: 0.7974\n",
            "val Loss: 0.6465 Acc: 0.7037\n",
            "train Loss: 0.5323 Acc: 0.7984\n",
            "val Loss: 0.9101 Acc: 0.6667\n"
          ]
        }
      ],
      "source": [
        "# Training loop using 5 epochs for now\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in dataloaders[phase]:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZTrPaR34HeR"
      },
      "outputs": [],
      "source": [
        "# Saving the model\n",
        "torch.save(model.state_dict(), 'lung_morbidity_classification.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMj3MhONytdf"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Defining the preprocessing function\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    input_tensor = preprocess(image)\n",
        "    input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension\n",
        "    return input_batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxpvUWtdzIZC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Defining the test directory path\n",
        "test_dir = '/content/drive/MyDrive/compiled_data/test'  # Replace with the path to your test directory\n",
        "\n",
        "# Storing the actual and predicted labels\n",
        "actual_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Iterating over each class directory\n",
        "for class_name in os.listdir(test_dir):\n",
        "    class_dir = os.path.join(test_dir, class_name)\n",
        "    if not os.path.isdir(class_dir):\n",
        "        continue\n",
        "\n",
        "    # Iterating over each image in the class directory\n",
        "    for image_name in os.listdir(class_dir):\n",
        "        image_path = os.path.join(class_dir, image_name)\n",
        "        if not os.path.isfile(image_path):\n",
        "            continue\n",
        "\n",
        "        # Preprocessing the image and making predictions\n",
        "        input_batch = preprocess_image(image_path).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_batch)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        predicted_class = preds.item()\n",
        "        actual_class = class_indices[class_name]\n",
        "\n",
        "        # Appending the actual and predicted labels\n",
        "        actual_labels.append(actual_class)\n",
        "        predicted_labels.append(predicted_class)\n",
        "\n",
        "# Calculating accuracy\n",
        "accuracy = accuracy_score(actual_labels, predicted_labels)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Comparing each prediction\n",
        "for actual, predicted in zip(actual_labels, predicted_labels):\n",
        "    print(f'Actual: {actual}, Predicted: {predicted}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XtTifYszRmb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}